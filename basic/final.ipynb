{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66e3441b",
   "metadata": {},
   "source": [
    "# Ollama 기본 사용법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e1db5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"당신: \")\n",
    "\n",
    "    if user_input == \"종료\":\n",
    "        break\n",
    "\n",
    "    chat_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "    response = ollama.chat(\n",
    "        model=\"EEVE-Korean-10.8B\",\n",
    "        messages=chat_history\n",
    "    )\n",
    "\n",
    "    print(\"EEVE: \", response['message']['content'])\n",
    "\n",
    "    chat_history.append({\"role\": \"assistant\", \"content\": response['message']['content']})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92bd859",
   "metadata": {},
   "source": [
    "# 임베딩 + RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d7a7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "import json\n",
    "\n",
    "embedding_model = SentenceTransformer(\"snunlp/KR-SBERT-V40K-klueNLI-augSTS\")\n",
    "client = chromadb.PersistentClient(\"./chromadb\")\n",
    "collection = client.get_or_create_collection(\"RAG_doc\")\n",
    "\n",
    "with open (\"characters/nara.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    RAG_doc = json.load(f)\n",
    "\n",
    "RAG_vector = embedding_model.encode(RAG_doc)\n",
    "\n",
    "collection_exist = collection.get(ids=[\"doc_0\"])\n",
    "\n",
    "if not collection_exist[\"documents\"]:\n",
    "    collection.add(\n",
    "        documents=RAG_doc,\n",
    "        embeddings=RAG_vector,\n",
    "        ids = [f\"doc_{i}\" for i in range(len(RAG_doc))]\n",
    "    )\n",
    "question = input(\"나:\")\n",
    "query_vector = embedding_model.encode(question).tolist()\n",
    "\n",
    "search_vectorDB = collection.query(query_embeddings=[query_vector], n_results=3)\n",
    "\n",
    "retrieved_contexts = search_vectorDB['documents'][0]\n",
    "context_str = \"\\n\".join(retrieved_contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f05548",
   "metadata": {},
   "source": [
    "# 대화 기록 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95e9ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "\n",
    "class InMemoryHistory (BaseChatMessageHistory):\n",
    "    def __init__(self):\n",
    "        self.messages = []\n",
    "\n",
    "    def add_messages(self, messages):\n",
    "        self.messages.extend(messages)\n",
    "    \n",
    "    def clear(self):\n",
    "        self.messages = []\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self.messages)\n",
    "    \n",
    "store = {}\n",
    "\n",
    "# session_id로 대화 내역 구분\n",
    "def get_by_session_id(session_id):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "history_test = get_by_session_id('test')\n",
    "history_test.add_messages(['hello', 'good mornig', 'how are you'])\n",
    "history_test.add_messages(['I am fine', 'Thank you'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09635be",
   "metadata": {},
   "source": [
    "# 프롬프트, 체인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981778a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# prompt 작성 예시\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', '너는 {skill}을 잘하는 AI 어시스턴트야.'), \n",
    "    # seesion_id = 'history'\n",
    "    MessagesPlaceholder(variable_name='history'),\n",
    "    ('human', '{query}')\n",
    "])\n",
    "\n",
    "model = ChatOllama(model=\"EEVE-Korean-10.8B\", temperature=.7)\n",
    "\n",
    "# prompt, model을 chain으로 묶음\n",
    "chain = prompt | model\n",
    "\n",
    "# chain\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history=get_by_session_id,\n",
    "    input_messages_key='query',\n",
    "    history_messages_key='history'\n",
    ")\n",
    "\n",
    "response = chain_with_history.invoke(\n",
    "    {'skill': '대화', 'query': '토끼는 농장에서 나무를 세 그루 키우고 있습니다.'},\n",
    "    config={'configurable': {'session_id': 'rabbit'}}\n",
    ")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062729f5",
   "metadata": {},
   "source": [
    "# Agent & Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219df287",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "\n",
    "tools = load_tools(['wikipedia', 'llm-math'], llm = model)\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    model,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    handle_parsing_error=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(agent.invoke('애니매이션 나루토의 등장인물 시카마루에 대해 설명해줘'))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
